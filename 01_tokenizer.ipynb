{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e5eb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"To be or not to be that is the question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b410665",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e636a138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1385, 413, 503, 625, 316, 413, 484, 382, 290, 4928]\n",
      "To be or not to be that is the question\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = enc.encode(s)\n",
    "decoded = enc.decode(tokens)\n",
    "\n",
    "print(tokens)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed4ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== tiktoken BPE Functions ===\n",
      "String: 'To be or not to be that is the question'\n",
      "\n",
      "encode(): [1385, 413, 503, 625, 316, 413, 484, 382, 290, 4928]\n",
      "decode(): 'To be or not to be that is the question'\n",
      "\n",
      "=== Individual tokens ===\n",
      "Token 1: 1385 → 'To'\n",
      "Token 2: 413 → ' be'\n",
      "Token 3: 503 → ' or'\n",
      "Token 4: 625 → ' not'\n",
      "Token 5: 316 → ' to'\n",
      "Token 6: 413 → ' be'\n",
      "Token 7: 484 → ' that'\n",
      "Token 8: 382 → ' is'\n",
      "Token 9: 290 → ' the'\n",
      "Token 10: 4928 → ' question'\n",
      "\n",
      "=== BPE with token control ===\n",
      "Vocabulary size: 200019\n",
      "Some example tokens from the BPE vocabulary:\n",
      "  Token 100: '�'\n",
      "  Token 200: '\f'\n",
      "  Token 300: ' �'\n",
      "  Token 400: 'ce'\n",
      "  Token 500: 'м'\n",
      "\n",
      "=== BPE Subword Splitting Examples ===\n",
      "'unhappiness' → BPE splits into: ['un', 'h', 'appiness']\n",
      "'preprocessing' → BPE splits into: ['pre', 'processing']\n",
      "'tokenization' → BPE splits into: ['token', 'ization']\n"
     ]
    }
   ],
   "source": [
    "# tiktoken already implements BPE - here are the key functions\n",
    "\n",
    "print(\"=== tiktoken BPE Functions ===\")\n",
    "print(f\"String: '{s}'\")\n",
    "print()\n",
    "\n",
    "# 1. Basic BPE encoding/decoding (what you already have)\n",
    "tokens = enc.encode(s)\n",
    "print(f\"encode(): {tokens}\")\n",
    "print(f\"decode(): '{enc.decode(tokens)}'\")\n",
    "print()\n",
    "\n",
    "# 2. Get individual token strings without decoding\n",
    "print(\"=== Individual tokens ===\")\n",
    "for i, token_id in enumerate(tokens):\n",
    "    # This is BPE in action - each token represents a subword/byte sequence\n",
    "    token_text = enc.decode([token_id])\n",
    "    print(f\"Token {i+1}: {token_id} → '{token_text}'\")\n",
    "print()\n",
    "\n",
    "# 3. Encoding with allowed/disallowed tokens (BPE control)\n",
    "# You can control which tokens are allowed\n",
    "print(\"=== BPE with token control ===\")\n",
    "# Example: encode with specific token restrictions\n",
    "try:\n",
    "    # This shows tiktoken's BPE vocabulary in action\n",
    "    print(f\"Vocabulary size: {enc.n_vocab}\")\n",
    "    print(\"Some example tokens from the BPE vocabulary:\")\n",
    "    for token_id in [100, 200, 300, 400, 500]:\n",
    "        try:\n",
    "            token_text = enc.decode([token_id])\n",
    "            print(f\"  Token {token_id}: '{token_text}'\")\n",
    "        except:\n",
    "            print(f\"  Token {token_id}: <invalid>\")\n",
    "except:\n",
    "    print(\"Could not access vocabulary size\")\n",
    "print()\n",
    "\n",
    "# 4. tiktoken automatically handles BPE merging\n",
    "print(\"=== BPE Subword Splitting Examples ===\")\n",
    "examples = [\"unhappiness\", \"preprocessing\", \"tokenization\"]\n",
    "for word in examples:\n",
    "    word_tokens = enc.encode(word)\n",
    "    print(f\"'{word}' → BPE splits into: {[enc.decode([t]) for t in word_tokens]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b48085c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Additional tiktoken BPE features ===\n",
      "Comparing different BPE models:\n",
      "gpt-4o         : 3 tokens → [497, 20454, 22990]\n",
      "gpt-3.5-turbo  : 3 tokens → [472, 16895, 11478]\n",
      "text-davinci-003: 3 tokens → [433, 9542, 4430]\n",
      "\n",
      "=== Special tokens in BPE ===\n",
      "Number of special tokens: 2\n",
      "Some special tokens: ['<|endofprompt|>', '<|endoftext|>']\n",
      "\n",
      "=== BPE encoding options ===\n",
      "Basic encoding: [1385, 413, 503, 625, 316, 413, 484, 382, 290, 4928]\n",
      "Safe encoding:  [1385, 413, 503, 625, 316, 413, 484, 382, 290, 4928]\n",
      "\n",
      "✅ tiktoken handles all BPE complexity internally!\n",
      "✅ You just need: encode() and decode() functions\n",
      "✅ The tokenization you see IS BPE working!\n",
      "text-davinci-003: 3 tokens → [433, 9542, 4430]\n",
      "\n",
      "=== Special tokens in BPE ===\n",
      "Number of special tokens: 2\n",
      "Some special tokens: ['<|endofprompt|>', '<|endoftext|>']\n",
      "\n",
      "=== BPE encoding options ===\n",
      "Basic encoding: [1385, 413, 503, 625, 316, 413, 484, 382, 290, 4928]\n",
      "Safe encoding:  [1385, 413, 503, 625, 316, 413, 484, 382, 290, 4928]\n",
      "\n",
      "✅ tiktoken handles all BPE complexity internally!\n",
      "✅ You just need: encode() and decode() functions\n",
      "✅ The tokenization you see IS BPE working!\n"
     ]
    }
   ],
   "source": [
    "# More tiktoken BPE features\n",
    "\n",
    "print(\"=== Additional tiktoken BPE features ===\")\n",
    "\n",
    "# 1. Different encoding models use different BPE vocabularies\n",
    "print(\"Comparing different BPE models:\")\n",
    "models = [\"gpt-4o\", \"gpt-3.5-turbo\", \"text-davinci-003\"]\n",
    "test_text = \"artificial intelligence\"\n",
    "\n",
    "for model in models:\n",
    "    try:\n",
    "        model_enc = tiktoken.encoding_for_model(model)\n",
    "        model_tokens = model_enc.encode(test_text)\n",
    "        print(f\"{model:15}: {len(model_tokens)} tokens → {model_tokens}\")\n",
    "    except:\n",
    "        print(f\"{model:15}: Not available\")\n",
    "print()\n",
    "\n",
    "# 2. tiktoken special tokens (part of BPE vocabulary)\n",
    "print(\"=== Special tokens in BPE ===\")\n",
    "try:\n",
    "    # Some models have special tokens\n",
    "    special_tokens = enc.special_tokens_set\n",
    "    print(f\"Number of special tokens: {len(special_tokens)}\")\n",
    "    if special_tokens:\n",
    "        print(\"Some special tokens:\", list(special_tokens)[:5])\n",
    "except:\n",
    "    print(\"No special tokens or not accessible\")\n",
    "print()\n",
    "\n",
    "# 3. Encode with different options\n",
    "print(\"=== BPE encoding options ===\")\n",
    "# Basic encoding\n",
    "basic_tokens = enc.encode(s)\n",
    "print(f\"Basic encoding: {basic_tokens}\")\n",
    "\n",
    "# Encoding with disallowed special tokens (safer for user input)\n",
    "try:\n",
    "    safe_tokens = enc.encode(s, disallowed_special=())\n",
    "    print(f\"Safe encoding:  {safe_tokens}\")\n",
    "except:\n",
    "    print(\"Safe encoding not available for this model\")\n",
    "    \n",
    "print()\n",
    "print(\"✅ tiktoken handles all BPE complexity internally!\")\n",
    "print(\"✅ You just need: encode() and decode() functions\")\n",
    "print(\"✅ The tokenization you see IS BPE working!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
